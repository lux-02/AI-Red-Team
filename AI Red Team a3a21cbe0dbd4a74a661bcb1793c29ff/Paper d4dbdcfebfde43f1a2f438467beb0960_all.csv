이름,Writer
"New prompt injection attack on ChatGPT web version.
Reckless copy-pasting may lead to serious privacy issues in your chat.",Roman Samoilenko
"Evaluating the Susceptibility of Pre-Trained Language Models via Handcrafted Adversarial Examples ",Hezekiah J. Branch
"Ignore This Title and HackAPrompt- Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition ",Sander Schulhoff
"LLaMA- Open and Efficient Foundation Language Models ",Hugo Touvron
Not what you’ve signed up for Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection,Kai Greshake
"ReAct- Synergizing Reasoning and Acting in Language Models ",Shunyu Yao
Red-Teaming for Generative AI- Silver Bullet or Security Theater?,Michael Feffer
Talking About Large Language Models,Murray Shanahan
"The Janus Interface- How Fine-Tuning in Large Language Models Amplifies the Privacy Risks ",Xiaoyi Chen
"Towards a Standard for Identifying and Managing Bias in Artificial Intelligence ",Reva Schwartz
"Universal Adversarial Triggers for Attacking and Analyzing NLP ",Eric Wallace
"Universal and Transferable Adversarial Attacks on Aligned Language Models ",Andy Zou
VAN,